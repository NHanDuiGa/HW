{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8be0234-260e-4e74-b421-156c0cd2bea6",
   "metadata": {},
   "source": [
    "**Note: For this assignment, you may only use standard Python and the `re` (Regular Expression) module. Advanced libraries such as NumPy, Pandas are not permitted**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803184f6",
   "metadata": {},
   "source": [
    "## Exercises 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96876e",
   "metadata": {},
   "source": [
    "Use `re.search` to find whether a string contains a phone number. The pattern that you write should detect a phone number in the following strings.  \n",
    "```\n",
    "\"Call me at 382-384-3840.\"  \n",
    "\"my number is (510) 849-3519. Call me!\"\n",
    "```  \n",
    "And not find a match in the following strings. \n",
    "```\n",
    "\"my number is 510-849-35192\"  \n",
    "\"here’s my number: 510-849.3519\"\n",
    "``` \n",
    "Consider making your own tests as well  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a578ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89249001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 382-384-3840. in → Call me at 382-384-3840.\n",
      "Found: (510) 849-3519. in → my number is (510) 849-3519. Call me!\n",
      "No match in → my number is 510-849-35192\n",
      "No match in → here’s my number: 510-849.3519\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "phone_pattern = r'\\(?\\d{3}\\)?[ -]\\d{3}-\\d{4}\\.'\n",
    "\n",
    "tests = [\n",
    "    \"Call me at 382-384-3840.\",\n",
    "    \"my number is (510) 849-3519. Call me!\",\n",
    "    \"my number is 510-849-35192\",\n",
    "    \"here’s my number: 510-849.3519\"\n",
    "]\n",
    "\n",
    "for text in tests:\n",
    "    match = re.search(phone_pattern, text)\n",
    "    if match:\n",
    "        print(f\"Found: {match.group()} in → {text}\")\n",
    "    else:\n",
    "        print(f\"No match in → {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1078e7f",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6c3fb",
   "metadata": {},
   "source": [
    "Use `re.sub` to alter the string below so that the dates have a common format that uses a dash for the day, month, and year separator.  \n",
    "```\n",
    "03/12/2018, 03.13.18, 03/14/2018, 03:15:2018\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70602df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-12-2018, 03-13-18, 03-14-2018, 03-15-2018'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "input_string = \"03/12/2018, 03.13.18, 03/14/2018, 03:15:2018\"\n",
    "date_pattern = r'(\\d{2})[/.:](\\d{2})[/.:](\\d{2,4})'\n",
    "replacement = r'\\1-\\2-\\3'\n",
    "output_string = re.sub(date_pattern, replacement, input_string)\n",
    "output_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa794a04",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce035dd6",
   "metadata": {},
   "source": [
    "Consider the first five sentences of the novel “Little Women” below. Extract the spoken dialog from each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997c791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Christmas won't be Christmas without any presents,\" grumbled Jo, lying on the rug.\n",
      "\"It's so dreadful to be poor!\" sighed Meg, looking down at her old dress.\n",
      "\"I don't think it's fair for some girls to have plenty of pretty things, and other girls nothing at all,\" added little Amy, with an injured sniff.\n",
      "\"We've got Father and Mother, and each other,\" said Beth contentedly from her corner.\n",
      "The four young faces on which the firelight shone brightened at the cheerful words, but darkened again as Jo said sadly, \"We haven't got Father, and shall not have him for a long time.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "\"Christmas won't be Christmas without any presents,\" grumbled Jo, lying on the rug.\n",
    "\"It's so dreadful to be poor!\" sighed Meg, looking down at her old dress.\n",
    "\"I don't think it's fair for some girls to have plenty of pretty things, and other girls nothing at all,\" added little Amy, with an injured sniff.\n",
    "\"We've got Father and Mother, and each other,\" said Beth contentedly from her corner.\n",
    "The four young faces on which the firelight shone brightened at the cheerful words, but darkened again as Jo said sadly, \"We haven't got Father, and shall not have him for a long time.\"\n",
    "'''\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df29ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: \"Christmas won't be Christmas without any presents,\"\n",
      "Sentence 2: \"It's so dreadful to be poor!\"\n",
      "Sentence 3: \"I don't think it's fair for some girls to have plenty of pretty things, and other girls nothing at all,\"\n",
      "Sentence 4: \"We've got Father and Mother, and each other,\"\n",
      "Sentence 5: \"We haven't got Father, and shall not have him for a long time.\"\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "sentences = [s.strip() for s in text.split('\\n') if s.strip()]\n",
    "dialogue_pattern = r'\"(.*?)\"'\n",
    "dialogues = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    match = re.search(dialogue_pattern, sentence)\n",
    "    if match:\n",
    "        dialogues.append(match.group(1))\n",
    "\n",
    "for i, dialogue in enumerate(dialogues):\n",
    "    print(f\"Sentence {i+1}: \\\"{dialogue}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b965d",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23288f5-57a1-4d63-b061-7ba77e4fa64d",
   "metadata": {},
   "source": [
    "In this exercise, you you working with ```email_test.txt``` file (attached), using Regular Expression.\\\n",
    "`Original Dataset: https://www.kaggle.com/datasets/rtatman/fraudulent-email-corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b6cb6b4-1ca3-438b-af64-d1c41a67f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: open file\n",
    "with open(\"email_test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "split_pattern = r'(?=^From r\\s+)'\n",
    "emails = re.split(split_pattern, data, flags=re.M)\n",
    "emails = [email for email in emails if email.strip()]\n",
    "total_emails = len(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20412e-72d3-4840-a048-a51c34c90765",
   "metadata": {},
   "source": [
    "#### Simple Fraudulent email detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f869f-3a65-4324-9dc9-f0e696addbed",
   "metadata": {},
   "source": [
    "1. Count how many emails contain urgency-related words (URGENT, IMMEDIATELY, QUICK, ASSISTANCE, CONFIDENTIAL). \n",
    "Calculate what percentage of emails use these tactics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7977f630-4f84-4957-9658-9ec671f13b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số email đã phân tích: 1330\n",
      "Số email chứa các từ khóa khẩn cấp: 1143\n",
      "Tỷ lệ phần trăm email sử dụng các chiến thuật này: 85.93984962406014%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "keywords = ['URGENT', 'IMMEDIATELY', 'QUICK', 'ASSISTANCE', 'CONFIDENTIAL']\n",
    "search_pattern = r'\\b(' + '|'.join(keywords) + r')\\b'\n",
    "    \n",
    "count_with_keywords = 0\n",
    "for email_content in emails:\n",
    "    if re.search(search_pattern, email_content, re.IGNORECASE):\n",
    "        count_with_keywords += 1\n",
    "        \n",
    "percentage = (count_with_keywords / total_emails) * 100\n",
    "        \n",
    "print(f\"Tổng số email đã phân tích: {total_emails}\")\n",
    "print(f\"Số email chứa các từ khóa khẩn cấp: {count_with_keywords}\")\n",
    "print(f\"Tỷ lệ phần trăm email sử dụng các chiến thuật này: {percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef15e5-861e-42e6-aba5-d087252c8568",
   "metadata": {},
   "source": [
    "2. Find all mentions of money amounts in the email bodies (e.g., `US$25M`, `$100,000.00`, `USD$31,000,000.00`). Calculate:\n",
    "- Total number of money mentions across all emails\n",
    "- The largest amount mentioned\n",
    "- The smallest amount mentioned\n",
    "- Average amount per email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697cd266-e892-4cb4-af0f-ecd2d369150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tổng số lượt đề cập đến tiền: 2169\n",
      "2. Số tiền lớn nhất được đề cập: $80,500,000,000,000,000.00\n",
      "3. Số tiền nhỏ nhất được đề cập: $0.00\n",
      "4. Số tiền trung bình mỗi email (Tổng tiền / Tổng email): $121,485,353,774,730.48\n"
     ]
    }
   ],
   "source": [
    "all_amounts = []\n",
    "money_pattern = r'((USD|US ?)\\$?|\\$)\\s*([\\d,.]+)\\s*(M|Million|B|Billion)?'\n",
    "\n",
    "for email_content in emails:\n",
    "    mentions = re.findall(money_pattern, email_content, re.IGNORECASE)\n",
    "    for match in mentions:\n",
    "        num_str = match[2]\n",
    "        suffix_str = match[3]\n",
    "        amount = None\n",
    "        \n",
    "        num_str = num_str.replace(',', '')\n",
    "        try:\n",
    "            amount = float(num_str)\n",
    "        except ValueError:\n",
    "            continue \n",
    "    \n",
    "        if suffix_str:\n",
    "            suffix_str_lower = suffix_str.lower()\n",
    "            if suffix_str_lower in ('m', 'million'):\n",
    "                amount *= 1_000_000\n",
    "            elif suffix_str_lower in ('b', 'billion'):\n",
    "                amount *= 1_000_000_000\n",
    "        \n",
    "        if amount is not None:\n",
    "            all_amounts.append(amount)\n",
    "\n",
    "if all_amounts:     \n",
    "    total_mentions = len(all_amounts)\n",
    "    max_amount = max(all_amounts)\n",
    "    min_amount = min(all_amounts)\n",
    "    total_sum = sum(all_amounts)\n",
    "    \n",
    "    average_per_email = 0\n",
    "    if total_emails > 0:\n",
    "        average_per_email = total_sum / total_emails\n",
    "            \n",
    "    print(f\"1. Tổng số lượt đề cập đến tiền: {total_mentions}\")\n",
    "    print(f\"2. Số tiền lớn nhất được đề cập: ${max_amount:,.2f}\")\n",
    "    print(f\"3. Số tiền nhỏ nhất được đề cập: ${min_amount:,.2f}\")\n",
    "    print(f\"4. Số tiền trung bình mỗi email (Tổng tiền / Tổng email): ${average_per_email:,.2f}\")\n",
    "else:\n",
    "    print(\"Không tìm thấy đề cập nào về tiền.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32421055-b63a-42b3-a614-ba04a7f7f652",
   "metadata": {},
   "source": [
    "3. Extract all mentions of deaths or deceased persons (e.g., \"late father\", \"died\", \"deceased\", \"death of\").\\\n",
    "   What percentage of emails use death as part of their story?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb9f0e18-71e8-4d4a-a862-2d5ea8b4c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số email sử dụng câu chuyện liên quan đến cái chết: 837\n",
      "Tỷ lệ phần trăm email sử dụng chiến thuật này: 62.93%\n"
     ]
    }
   ],
   "source": [
    "simple_words = [\n",
    "    'died',\n",
    "    'deceased',\n",
    "    'death',\n",
    "    'dead',\n",
    "    'assassinated',\n",
    "    'assassination',\n",
    "    'demise',\n",
    "    'passed away',\n",
    "    'killed',\n",
    "    'fatalities',\n",
    "    'casualties'\n",
    "]\n",
    "\n",
    "special_patterns = [\n",
    "    'late ',         \n",
    "    'lost .* lives' \n",
    "]\n",
    "\n",
    "p1 = r'\\b(' + '|'.join(simple_words) + r')\\b'\n",
    "p2 = r'(' + '|'.join(special_patterns) + r')'\n",
    "death_pattern = p1 + '|' + p2\n",
    "\n",
    "count_with_death = 0\n",
    "for email_content in emails:\n",
    "    if re.search(death_pattern, email_content, re.IGNORECASE):\n",
    "        count_with_death += 1\n",
    "                \n",
    "percentage_death = 0.0\n",
    "if total_emails > 0:\n",
    "    percentage_death = (count_with_death / total_emails) * 100\n",
    "  \n",
    "print(f\"Số email sử dụng câu chuyện liên quan đến cái chết: {count_with_death}\")\n",
    "print(f\"Tỷ lệ phần trăm email sử dụng chiến thuật này: {percentage_death:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6c648-80f1-4d96-9868-8539688f9174",
   "metadata": {},
   "source": [
    "4. Many emails mention percentage splits of money (e.g., \"70% for us\", \"20% for you\", \"10% for expenses\"). \\\n",
    "   Extract all percentage distributions and identify the most common split pattern offered to recipients.\n",
    "\n",
    "   Example: most common split patterns:\\\n",
    "   70% - 20% - 10%: appears 15 times\\\n",
    "   75% - 20% - 5%: appears 12 times\\\n",
    "    60% - 30% - 10%: appears 8 times\\\n",
    "    80% - 15% - 5%: appears 6 times\\\n",
    "    55% - 30% - 10% - 5%: appears 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbe4e05-4535-4166-86f5-3be203a79897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60% - 30% - 10%: xuất hiện 78 lần\n",
      "70% - 25% - 5%: xuất hiện 72 lần\n",
      "70% - 20% - 10%: xuất hiện 50 lần\n",
      "75% - 20% - 5%: xuất hiện 37 lần\n",
      "60% - 35% - 5%: xuất hiện 36 lần\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "split_patterns_counter = {}\n",
    "percentage_pattern = r'(\\d+)%'\n",
    "\n",
    "for email_content in emails:       \n",
    "    percentages_str = re.findall(percentage_pattern, email_content)\n",
    "    percentages_int = []\n",
    "    for p_str in percentages_str:\n",
    "        p_int = int(p_str)\n",
    "        if 0 < p_int < 100:\n",
    "            percentages_int.append(p_int)\n",
    "        \n",
    "    if len(percentages_int) >= 2:\n",
    "        percentages_int.sort(reverse=True)\n",
    "        pattern_tuple = tuple(percentages_int)\n",
    "        current_count = split_patterns_counter.get(pattern_tuple, 0)\n",
    "        split_patterns_counter[pattern_tuple] = current_count + 1\n",
    "    \n",
    "sorted_splits = sorted(\n",
    "    split_patterns_counter.items(), \n",
    "    key=lambda item: item[1], \n",
    "    reverse=True\n",
    ")\n",
    "        \n",
    "for pattern_tuple, count in sorted_splits[:5]:\n",
    "    pattern_str = \" - \".join([f\"{p}%\" for p in pattern_tuple])\n",
    "    print(f\"{pattern_str}: xuất hiện {count} lần\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7f2f3-2613-4657-95e6-c953286ebdb7",
   "metadata": {},
   "source": [
    "5. Create a \"scam score\" for each email based on:\\\n",
    "    Urgency keywords (1 point each)\\\n",
    "    Money mentions (2 points each)\\\n",
    "    Percentages offered (1 point each)\\\n",
    "    Death mentions (1 point)\\\n",
    "    ALL CAPS usage (1 point if >20% of text)\n",
    "\n",
    "    ***Rank the top 10 highest-scoring emails*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900f4359-c2a3-4566-a2f1-b240069a94ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Email 788: Scam score = 71\n",
      "   Preview:  Wed Apr  7 09:38:50 2004 Return-Path: <monicamtf11@galmail.co.za> From: \"monica martins\" <monicamtf...\n",
      "\n",
      "2. Email 593: Scam score = 43\n",
      "   Preview:  Tue Dec  9 19:48:27 2003 Return-Path: <dr_usmanbello@fsmail.net> Message-ID: <30547158.107101727432...\n",
      "\n",
      "3. Email 134: Scam score = 34\n",
      "   Preview:  Thu Feb 27 08:25:50 2003 Return-Path: <drabdullrasaq@phantomemail.com> Message-Id: <200302271324.h1...\n",
      "\n",
      "4. Email 591: Scam score = 32\n",
      "   Preview:  Fri Dec  5 12:06:18 2003 Return-Path: <ebaye52@yahoo.co.uk> Message-ID: <20031205170606.77721.qmail...\n",
      "\n",
      "5. Email 244: Scam score = 30\n",
      "   Preview:  Fri May 30 05:50:47 2003 Return-Path: <chuksanthony05@netscape.net> Message-Id: <200305300950.h4U9o...\n",
      "\n",
      "6. Email 533: Scam score = 30\n",
      "   Preview:  Wed Nov  5 08:17:16 2003 Return-Path: <jamesmorgan@fsmail.net> Message-ID: <30401587.1068038230059....\n",
      "\n",
      "7. Email 945: Scam score = 29\n",
      "   Preview:  Mon Jun 14 17:00:08 2004 \tby webmail.postino.it (IMP) with HTTP  \tfor <contactiyang@postino.it@212....\n",
      "\n",
      "8. Email 80: Scam score = 28\n",
      "   Preview:  Tue Jan 21 13:16:00 2003 Return-Path: <chris_adamu2003@yahoo.com> Message-ID: <20030121174457.32609...\n",
      "\n",
      "9. Email 55: Scam score = 27\n",
      "   Preview:  Mon Dec 30 04:15:59 2002 Return-Path: <obileonard@yahoo.com> Message-ID: <20021230091415.71715.qmai...\n",
      "\n",
      "10. Email 394: Scam score = 27\n",
      "   Preview:  Mon Sep  1 08:56:35 2003 Return-Path: <akumembeki@netscape.net> From: MASTER HAROLD MBEKI <akumembe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "scam_scores = []\n",
    "\n",
    "for email_content in emails:\n",
    "    score = 0\n",
    "    \n",
    "    urgency_matches = re.findall(search_pattern, email_content, re.IGNORECASE)\n",
    "    score += len(urgency_matches) * 1\n",
    "\n",
    "    money_mentions = re.findall(money_pattern, email_content, re.IGNORECASE)\n",
    "    score += len(money_mentions) * 2\n",
    "\n",
    "    percentages_str = re.findall(percentage_pattern, email_content)\n",
    "    percentages_int = [int(p) for p in percentages_str if 0 < int(p) < 100]\n",
    "    score += len(percentages_int) * 1\n",
    "\n",
    "    if re.search(death_pattern, email_content, re.IGNORECASE):\n",
    "        score += 1\n",
    "\n",
    "    letters = [c for c in email_content if c.isalpha()]\n",
    "    if letters:\n",
    "        num_upper = sum(1 for c in letters if c.isupper())\n",
    "        if num_upper / len(letters) > 0.2:\n",
    "            score += 1\n",
    "\n",
    "    scam_scores.append(score)\n",
    "\n",
    "email_scores_with_index = list(enumerate(scam_scores))\n",
    "top_emails = sorted(email_scores_with_index, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "for rank, (idx, score) in enumerate(top_emails, start=1):\n",
    "    email_preview = emails[idx][:100].replace(\"\\n\", \" \") + \"...\" \n",
    "    print(f\"{rank}. Email {idx+1}: Scam score = {score}\")\n",
    "    print(f\"   Preview: {email_preview}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9b64d-8e96-46fc-870a-286f13c495ad",
   "metadata": {},
   "source": [
    "6. Identify emails that appear to be duplicates or near-duplicates (same sender, similar subject, sent within 24 hours). How many duplicate emails exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e0ca4cc-9c96-48da-b757-d23fc0d1d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số email duplicate hoặc gần-duplicate: 356\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "duplicate_pairs = []\n",
    "duplicate_indices = set() \n",
    "\n",
    "for i in range(len(emails)):\n",
    "    for j in range(i + 1, len(emails)):\n",
    "        e1 = emails[i]\n",
    "        e2 = emails[j]\n",
    "    \n",
    "        sender_match1 = re.search(r'^From:\\s*(.+)$', e1, re.M)\n",
    "        sender_match2 = re.search(r'^From:\\s*(.+)$', e2, re.M)\n",
    "        sender1 = sender_match1.group(1).strip() if sender_match1 else \"unknown1\"\n",
    "        sender2 = sender_match2.group(1).strip() if sender_match2 else \"unknown2\"\n",
    "        \n",
    "        if sender1 != sender2:\n",
    "            continue\n",
    "\n",
    "        subject_match1 = re.search(r'^Subject:\\s*(.+)$', e1, re.M)\n",
    "        subject_match2 = re.search(r'^Subject:\\s*(.+)$', e2, re.M)\n",
    "        subject1 = subject_match1.group(1).strip().lower() if subject_match1 else \"\"\n",
    "        subject2 = subject_match2.group(1).strip().lower() if subject_match2 else \"\"\n",
    "        \n",
    "        if subject1 != subject2:\n",
    "            continue\n",
    "        \n",
    "        date_match1 = re.search(r'^Date:\\s*(.+)$', e1, re.M)\n",
    "        date_match2 = re.search(r'^Date:\\s*(.+)$', e2, re.M)\n",
    "\n",
    "        if not date_match1 or not date_match2:\n",
    "            continue\n",
    "\n",
    "        date_str1 = date_match1.group(1).strip()\n",
    "        date_str2 = date_match2.group(1).strip()\n",
    "        \n",
    "        try:\n",
    "            date_str1_clean = re.sub(r'\\s*\\([A-Za-z]+\\)\\s*$', '', date_str1)\n",
    "            date_str2_clean = re.sub(r'\\s*\\([A-Za-z]+\\)\\s*$', '', date_str2)\n",
    "\n",
    "            date_format = \"%a, %d %b %Y %H:%M:%S %z\"\n",
    "            \n",
    "            dt1 = datetime.strptime(date_str1_clean, date_format)\n",
    "            dt2 = datetime.strptime(date_str2_clean, date_format)\n",
    "            time_difference = abs(dt1 - dt2)\n",
    "\n",
    "            if time_difference > timedelta(hours=24):\n",
    "                continue\n",
    "                \n",
    "        except ValueError:\n",
    "            try:\n",
    "                date_format_no_day = \"%d %b %Y %H:%M:%S %z\"\n",
    "                dt1 = datetime.strptime(date_str1_clean, date_format_no_day)\n",
    "                dt2 = datetime.strptime(date_str2_clean, date_format_no_day)\n",
    "                \n",
    "                time_difference = abs(dt1 - dt2)\n",
    "                if time_difference > timedelta(hours=24):\n",
    "                    continue\n",
    "            except ValueError:\n",
    "                continue\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "        duplicate_indices.add(i)\n",
    "        duplicate_indices.add(j)\n",
    "\n",
    "print(f\"Tổng số email duplicate hoặc gần-duplicate: {len(duplicate_indices)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "480a220089555a41f3a156eb9bb9648c7435afde896ef7949f2cdd3a44c0a0fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
